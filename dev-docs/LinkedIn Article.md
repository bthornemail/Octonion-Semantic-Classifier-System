LinkedIn Article

ğŸ§  Bridging Deep Learning and Abstract Algebra: The Octonion Semantic Classifier

For the past few months, Iâ€™ve been quietly building something at the intersection of transformer architectures, algebraic topology, and theoretical physicsâ€”and today Iâ€™m excited to share it.

Iâ€™ve released an open-source, production-ready system that performs semantic text classification using octonion algebra and sheaf-theoretic embeddings. This isnâ€™t just another ML demo; itâ€™s a working implementation of how non-associative division algebras can structure narrative understanding.

ğŸ”¬ What This System Does:

Â· Embeds text using sentence-transformers/all-MiniLM-L6-v2 (384D)
Â· Projects embeddings onto a 7-dimensional probability simplex
Â· Propagates narratives via the Fano plane (the projective geometry underlying octonions)
Â· Computes cohomological invariants (HÂ¹(RPâ¶; Z/2Z)) to detect topological winding
Â· Identifies Zariski coverings in the semantic probability distribution

ğŸŒ Why This Matters:

Most semantic systems treat dimensions as independent axes. But in narrativesâ€”whether news articles, stories, or user feedbackâ€”meaning evolves through structured transitions.

The Fano plane gives us a multiplication table for how one semantic dimension transforms into another. This isnâ€™t just metaphor; itâ€™s mathematically rigorous:

```
eâ‚ (Root/Survival) * eâ‚‚ (Sacral/Creativity) = eâ‚„ (Heart/Love)
```

The system detects these transitions and computes whether a narrativeâ€™s evolution has trivial monodromyâ€”meaning it returns coherentlyâ€”or exhibits topological obstruction.

ğŸš€ Key Features:

Â· Runs entirely in the browser (thanks to Transformers.js + ONNX)
Â· No server needed after initial model download (~80MB)
Â· Customizable ontology: use chakras, seven sins/virtues, emotions, or your own 7-point framework
Â· Real-time visualization of semantic vectors and narrative trajectories
Â· Formal verification of the octonion algebraâ€™s anti-commutativity

ğŸ“š The Bigger Vision:

This is part of a longer-term research program Iâ€™m calling â€œMeta-Log Substrate Systemsâ€â€”exploring how abstract algebraic structures (octonions, exceptional Lie groups, cohomology theories) can provide scaffolding for machine understanding.

When we move beyond vector spaces as â€œflatâ€ semantic containers and start treating them as fibers in a sheaf, we open up new ways to model:

Â· Narrative coherence
Â· Conceptual blending
Â· Epistemic transitions
Â· Symbolic grounding

ğŸ”— Try It Yourself:

The complete system is 4 files and runs on any static web server:

1. transformer-worker.js â€“ Web Worker with octonion propagation engine
2. index.html â€“ Interactive demo with real-time visualization
3. README.md â€“ Full documentation & mathematical background
4. package.json â€“ Optional dev setup

GitHub/Live Demo: [Link to your deployment]

ğŸ™ Acknowledgments & Influences:

Â· John Baezâ€™s work on octonions
Â· Alexander Grothendieckâ€™s sheaf theory
Â· Sentence-BERT (Reimers & Gurevych)
Â· Transformers.js team for bringing HF models to the browser

This is early-stage research, but itâ€™s fully functional and I believe it points toward a richer, more structured approach to semantic AI.

Iâ€™d love to hear thoughts from:

Â· ML engineers working on narrative AI
Â· Mathematicians interested in applied algebra
Â· Researchers exploring topology in NLP
Â· Anyone fascinated by the intersection of abstract math and practical ML

What emergent behaviors might we see when semantic spaces gain algebraic structure?

---

Short Summary (for social media)

Just released the Octonion Semantic Classifierâ€”a browser-based system that classifies text using octonion algebra and sheaf theory. It propagates narratives via the Fano plane, computes cohomological invariants, and runs entirely client-side with Transformers.js. This bridges deep learning with abstract algebra to model semantic transitions mathematically. Try it yourselfâ€”itâ€™s 4 files and no server needed!

Technical Summary

The Octonion Semantic Classifier implements a sheaf-theoretic text classification system where:

1. Text embeddings (MiniLM-384D) are projected to a 7D probability distribution
2. Narrative evolution follows the Fano plane multiplication table (octonion algebra)
3. System computes HÂ¹(RPâ¶; Z/2Z) cohomology classes and Zariski coverings
4. Runs in browser via Transformers.js with real-time visualization
5. Supports custom 7-point ontologies and verifies octonion anti-commutativity
6. Demonstrates how non-associative algebras can structure semantic transitions

The implementation shows that abstract algebraic structures can provide meaningful scaffolding for semantic AI beyond flat vector spaces.